name: E2E Tests

on:
  push:
    branches:
      - main
  schedule:
    - cron: '0 5 * * *'  # Runs every day at 5 AM UTC
  workflow_dispatch:
    inputs:
      simplyblock_csi_branch:
        description: ''
        required: true
        default: 'master'
      sbcli_cmd:
        description: ''
        required: true
        default: 'sbcli-dev'
      upload_logs:
        description: 'Upload logs to AWS'
        required: false
        default: false
        type: boolean
jobs:
  e2e:
    # # runs-on: self-hosted
    # concurrency:
    #   group: ${{ github.workflow }}
    #   cancel-in-progress: false
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set upload_logs for scheduled and push events
        if: github.event_name == 'schedule' || github.event_name == 'push'
        run: echo "upload_logs=true" >> $GITHUB_ENV

      - name: Set upload_logs for manual workflow_dispatch
        if: github.event_name == 'workflow_dispatch'
        run: echo "upload_logs=${{ github.event.inputs.upload_logs }}" >> $GITHUB_ENV

      - uses: actions/setup-go@v5
        with:
          go-version: '1.22'
      - run: go version

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_wrapper: false

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

      - name: Install Helm
        run: |
          curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
          chmod 700 get_helm.sh
          ./get_helm.sh

      - name: Initialize Terraform
        run: |
          export TFSTATE_BUCKET=simplyblock-terraform-state-bucket
          export TFSTATE_KEY=csi
          export TFSTATE_REGION=us-east-2
          export TFSTATE_DYNAMODB_TABLE=terraform-up-and-running-locks

          terraform init -reconfigure \
            -backend-config="bucket=${TFSTATE_BUCKET}" \
            -backend-config="key=${TFSTATE_KEY}" \
            -backend-config="region=${TFSTATE_REGION}" \
            -backend-config="dynamodb_table=${TFSTATE_DYNAMODB_TABLE}" \
            -backend-config="encrypt=true"

      - name: select or create workspace
        run: terraform workspace select -or-create githubactions

      - name: Validate Terraform Configuration
        run: terraform validate

      - name: Plan Terraform Changes
        run: |
          terraform plan \
            -var "mgmt_nodes=1" \
            -var "storage_nodes=3" \
            -var "storage_nodes_arch=amd64" \
            -var "storage_nodes_instance_type=m6i.2xlarge" \
            -var "sec_storage_nodes_instance_type=m6i.2xlarge" \
            -var "sec_storage_nodes=0" \
            -var "snode_deploy_on_k8s=true" \
            -var "extra_nodes=1" \
            -var "extra_nodes_instance_type=m6id.xlarge" \
            -var "extra_nodes_arch=amd64" \
            -var "region=us-east-2" \
            -var "sbcli_cmd=${{ github.event.inputs.sbcli_cmd || 'sbcli-dev' }}" \
            -out=tfplan
            
      - name: Apply Terraform Changes
        run: terraform apply tfplan

      - name: Bootstrap Cluster
        run: $GITHUB_WORKSPACE/bootstrap-cluster.sh --max-lvol 10 --max-snap 10 --max-size 150g --number-of-devices 1 --journal-partition 0 --k8s-snode
        id: bootstrap_cluster
        env:
          SBCLI_CMD: ${{ github.event.inputs.sbcli_cmd || 'sbcli-dev' }}

      - name: Bootstrap K3s
        run: $GITHUB_WORKSPACE/bootstrap-k3s.sh --k8s-snode
        id: bootstrap_k3s

      - name: copying  Kubeconfig file
        run: |
          mkdir -p ${HOME}/.kube
          scp -o StrictHostKeyChecking=no -i ${{ steps.bootstrap_k3s.outputs.KEY }} ec2-user@${{ steps.bootstrap_k3s.outputs.extra_node_ip }}:/etc/rancher/k3s/k3s.yaml ${HOME}/.kube/config

      - name: update .kube/config address
        run: |
          sed -i "s/127.0.0.1/${{ steps.bootstrap_k3s.outputs.extra_node_ip }}/g" ${HOME}/.kube/config

      - name: Clone simplyblock-csi repo
        run: git clone -b ${{ github.event.inputs.simplyblock_csi_branch || 'master'}} https://github.com/simplyblock-io/simplyblock-csi.git

      - name: Install SPDK-CSI using Helm
        run: |
          cd simplyblock-csi/charts/spdk-csi/latest/spdk-csi
          helm install -n simplyblk --create-namespace spdk-csi ./ \
             --set csiConfig.simplybk.uuid=${{ steps.bootstrap_cluster.outputs.cluster_id }} \
             --set csiConfig.simplybk.ip=${{ steps.bootstrap_cluster.outputs.cluster_api_gateway_endpoint }} \
             --set csiSecret.simplybk.secret=${{ steps.bootstrap_cluster.outputs.cluster_secret }} \
             --set logicalVolume.pool_name=testing1 \
             --set image.simplyblock.tag=main \
             --set image.spdkcsi.tag=master-arm64 \
             --set storagenode.create=true \
             --set cachingnode.create=false \
             --set logicalVolume.encryption=true

      - name: Apply configuration
        run: |
          cd simplyblock-csi/scripts
          chmod +x config-apply.sh
          ./config-apply.sh

      - name: Reboot Workers
        run: |
          $GITHUB_WORKSPACE/reboot-worker.sh

      - name: Install SIMPLYBLK-CONTROLLER using Helm
        run: |
          cd simplyblock-csi/charts/sb-controller/latest
          helm install -n simplyblk --create-namespace sb-controller ./ \
             --set storagenode.create=true \
             --set cachingnode.create=false 

      - name: Check Cluster Status
        run: |
          CLUSTER_API_GATEWAY_ENDPOINT=${{ steps.bootstrap_cluster.outputs.cluster_api_gateway_endpoint }}
          CLUSTER_UUID=${{ steps.bootstrap_cluster.outputs.cluster_id }}
          CLUSTER_SECRET=${{ steps.bootstrap_cluster.outputs.cluster_secret }}
          n=0
          until [ "$n" -ge 60 ]
          do
            response=$(curl -s -X GET "$CLUSTER_API_GATEWAY_ENDPOINT/cluster/$CLUSTER_UUID" \
              -H "Content-Type: application/json" \
              -H "Authorization: $CLUSTER_UUID $CLUSTER_SECRET")
            
            status=$(echo $response | jq -r '.results[0].status')
            
            if [ "$status" != "active" ]; then
                echo "Cluster status is not active, current status: $status, retrying"
                n=$((n+1)) 
                sleep 10
            else
                echo "Cluster status is active"
                exit 0
            fi
          done
          echo "Cluster status is not active"
          exit 1

                  
      - name: Run tests
        run: |
          cd simplyblock-csi
          echo "Running tests in namespace ${{ steps.get-namespace.outputs.namespace }}"
          export CSI_NAMESPACE=spdk-csi
          export CGO_ENABLED=1
          make e2e-test E2E_TEST_ARGS="--ginkgo.focus=\"SPDKCSI-(NVMEOF|SNAPSHOT|CLONE|NodeRestart)\" --ginkgo.dry-run"

      - name: Upload docker logs to s3
        run: |
          if [[ "${{ github.event_name }}" == 'schedule' || "${{ env.upload_logs }}" == 'true' ]]; then
            $GITHUB_WORKSPACE/upload_docker_logs_to_s3.sh --k8s --namespace "spdk-csi"
          else
            $GITHUB_WORKSPACE/upload_docker_logs_to_s3.sh
          fi
        if: always()
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          S3_BUCKET_NAME: "simplyblock-e2e-test-logs"
          RUN_ID: ${{ github.run_id }}

      - name: Send Slack Notification
        if: always()
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          if [[ ${{ job.status }} == 'success' ]]; then
            curl -X POST -H 'Content-type: application/json' --data '{"text":"Kubernetes E2E tests successfully completed!"}' $SLACK_WEBHOOK_URL
          else
            curl -X POST -H 'Content-type: application/json' --data '{"text":"Kubernetes E2E tests failed!"}' $SLACK_WEBHOOK_URL
          fi

      - name: Destroy Cluster
        if: always()
        run: terraform destroy --auto-approve

      - name: 'Cleanup build folder'
        run: |
          ls -la ./
          rm -rf ./* || true
          rm -rf ./.??* || true
          ls -la ./
