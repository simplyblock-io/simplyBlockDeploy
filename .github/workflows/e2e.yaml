name: E2E Tests

on:
  push:
    branches:
      - main
      - switch_to_workspace
  schedule:
    - cron: '0 5 * * *'  # Runs every day at 5 AM UTC
  workflow_dispatch:

jobs:
  e2e:
    runs-on: ubuntu-latest
    concurrency:
      group: ${{ github.workflow }}
      cancel-in-progress: false
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_wrapper: false

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

      - name: Install Helm
        run: |
          curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
          chmod 700 get_helm.sh
          ./get_helm.sh

      - name: Initialize Terraform
        run: terraform init

      - name: select or create workspace
        run: terraform workspace select -or-create githubactions

      - name: Validate Terraform Configuration
        run: terraform validate

      - name: Plan Terraform Changes
        run: |
          terraform plan \
            -var "mgmt_nodes=1" -var "storage_nodes=3" \
            -var "extra_nodes=1" -var "extra_nodes_instance_type=m6id.large" \
            -var "region=us-east-2" -out=tfplan

      - name: Apply Terraform Changes
        run: terraform apply tfplan

      - name: Bootstrap Cluster
        run: $GITHUB_WORKSPACE/bootstrap-cluster.sh --memory 8g --cpu-mask 0x3 --iobuf_small_pool_count 10000 --iobuf_large_pool_count 25000
        id: bootstrap_cluster

      - name: Bootstrap K3s
        run: $GITHUB_WORKSPACE/bootstrap-k3s.sh
        id: bootstrap_k3s

      - name: copying  Kubeconfig file
        run: |
          mkdir -p ${HOME}/.kube
          scp -o StrictHostKeyChecking=no -i ${{ steps.bootstrap_k3s.outputs.KEY }} ec2-user@${{ steps.bootstrap_k3s.outputs.extra_node_ip }}:/etc/rancher/k3s/k3s.yaml ${HOME}/.kube/config

      - name: update .kube/config address
        run: |
          sed -i "s/127.0.0.1/${{ steps.bootstrap_k3s.outputs.extra_node_ip }}/g" ${HOME}/.kube/config

      - name: Clone spdk-csi repo
        run: git clone https://github.com/simplyblock-io/spdk-csi.git

      - name: Label Node type=cache
        run: |
          nodes=$(kubectl get nodes -o jsonpath='{.items[*].metadata.name}')

          for node in $nodes; do
              kubectl label nodes $node type=cache
          done

          kubectl get nodes --show-labels

      - name: Install SPDK-CSI using Helm
        run: |
          cd spdk-csi/charts/latest/spdk-csi
          helm install -n spdk-csi --create-namespace spdk-csi ./ \
             --set csiConfig.simplybk.uuid=91b07c92-5831-466a-84fc-3743156c2a49 \
             --set csiConfig.simplybk.ip=https://prtzjsfa6j.execute-api.us-east-1.amazonaws.com \
             --set csiSecret.simplybk.secret=DK8IXLg3C6q12dldDP0L \
             --set logicalVolume.pool_name=testing1 \
             --set image.simplyblock.tag=dev

      - name: Run tests
        run: |
          cd spdk-csi
          echo "Running tests in namespace ${{ steps.get-namespace.outputs.namespace }}"
          export CSI_NAMESPACE=spdk-csi
          make e2e-test

      - name: Upload docker logs to s3
        run: $GITHUB_WORKSPACE/upload_docker_logs_to_s3.sh
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          S3_BUCKET_NAME: "simplyblock-terraform-state-bucket"

      - name: Send Slack Notification
        if: always()
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          if [[ ${{ job.status }} == 'success' ]]; then
            curl -X POST -H 'Content-type: application/json' --data '{"text":"Kubernetes E2E tests successfully completed!"}' $SLACK_WEBHOOK_URL
          else
            curl -X POST -H 'Content-type: application/json' --data '{"text":"Kubernetes E2E tests failed!"}' $SLACK_WEBHOOK_URL
          fi

      - name: Destroy Cluster
        if: always()
        run: terraform destroy --auto-approve
